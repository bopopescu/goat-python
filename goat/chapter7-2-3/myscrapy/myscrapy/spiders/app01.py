# -*- coding: utf-8 -*-
import scrapy

'''
抓取网页数据 并保存到本地  请求方式一
定义 start_urls 属性 并且和 def parse(self, response): 配合使用
'''
class App01Spider(scrapy.Spider):
    name = 'app01'
    # 爬虫实验室 首页第一页记录
    start_urls = [ 'http://lab.scrapyd.cn/page/1/', ]


    def parse(self, response):
        # response.url ：'http://lab.scrapyd.cn/page/1/'  以"/"分隔  取倒数第二个元素 这里为1
        page = response.url.split("/")[-2]
        # 字符串的格式化输出 %s 被 page 替代 结果为 mingyan-1.html
        filename = 'mingyan-%s.html' % page
        # 以 'wb' 模式打开文件
        with open(filename, 'wb') as f:
            # 将请求体写入文件
          f.write(response.body)
        self.log('保存文件: %s' % filename)

''' With open函数打开文件的各种方式
r	以只读方式打开文件。文件的指针将会放在文件的开头。这是默认模式。
w	打开一个文件只用于写入。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。
a	打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。
rb	以二进制格式打开一个文件用于只读。文件指针将会放在文件的开头。这是默认模式。
wb	以二进制格式打开一个文件只用于写入。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。
ab	以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。
r+	打开一个文件用于读写。文件指针将会放在文件的开头。
w+	打开一个文件用于读写。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。
a+	打开一个文件用于读写。如果该文件已存在，文件指针将会放在文件的结尾。文件打开时会是追加模式。如果该文件不存在，创建新文件用于读写。
rb+	以二进制格式打开一个文件用于读写。文件指针将会放在文件的开头。
wb+	以二进制格式打开一个文件用于读写。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。
ab+	以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。如果该文件不存在，创建新文件用于读写。

'''